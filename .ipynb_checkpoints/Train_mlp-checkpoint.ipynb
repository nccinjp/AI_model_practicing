{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f6dc1f",
   "metadata": {},
   "source": [
    "# Train_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5985fac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Bull</th>\n",
       "      <th>Bear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>901</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>250</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Bull  Bear\n",
       "0   train   901   789\n",
       "1     val   250   233\n",
       "2    test   119   119"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CLASSES = [ \"Bull\" ,  \"Bear\" ] \n",
    "LABEL_BULL = CLASSES.index(\"Bull\")\n",
    "LABEL_BEAR = CLASSES.index(\"Bear\")\n",
    "\n",
    "datasets = np.load(\"datasets.npz\")\n",
    "x_train,y_train = datasets[\"x_train\"], datasets[\"y_train\"]\n",
    "x_val, y_val = datasets[\"x_val\"], datasets[\"y_val\"]\n",
    "x_test, y_test = datasets[\"x_test\"], datasets[\"y_test\"]\n",
    "\n",
    "# Label distribution\n",
    "label_distribution = pd.DataFrame([{\"Dataset\" : \"train\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_train == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_train == LABEL_BEAR)},\n",
    "                                                         {\"Dataset\" : \"val\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_val == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_val == LABEL_BEAR)},\n",
    "                                                         {\"Dataset\" : \"test\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_test == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_test == LABEL_BEAR)}])\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492acd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1690, 100, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474c21d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1690 * 100 *7    # total trainning datas amount "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34192011",
   "metadata": {},
   "source": [
    "# Construct model モデルの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a7aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 7)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 700)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               179456    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,762\n",
      "Trainable params: 245,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Build model\n",
    "n_time_steps = x_train.shape[1]\n",
    "n_features = x_train.shape[ 2 ]\n",
    "\n",
    "input_layer = Input(shape = (n_time_steps , n_features))\n",
    "x = Flatten()(input_layer)\n",
    "x = Dense(256, activation = \"relu\")(x)  #ノード\n",
    "x = Dense(256, activation = \"relu\")(x) # ノード\n",
    "output_layer = Dense(len(CLASSES), activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs = output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324856bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if trainable params is too big , bigger than tainning datas a lot  it will  be overfit problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42b526",
   "metadata": {},
   "source": [
    "# Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abe0752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 18711188.0000 - accuracy: 0.4574INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 2s 2s/step - loss: 18711188.0000 - accuracy: 0.4574 - val_loss: 99758392.0000 - val_accuracy: 0.5176\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 97367688.0000 - accuracy: 0.5331INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 97367688.0000 - accuracy: 0.5331 - val_loss: 82457440.0000 - val_accuracy: 0.5176\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 80500376.0000 - accuracy: 0.5331INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 80500376.0000 - accuracy: 0.5331 - val_loss: 39803548.0000 - val_accuracy: 0.5176\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 38619744.0000 - accuracy: 0.5331INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 38619744.0000 - accuracy: 0.5331 - val_loss: 11619760.0000 - val_accuracy: 0.4824\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12842953.0000 - accuracy: 0.4710 - val_loss: 26354478.0000 - val_accuracy: 0.4824\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 28590332.0000 - accuracy: 0.4669 - val_loss: 18490306.0000 - val_accuracy: 0.4824\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 20243390.0000 - accuracy: 0.4680INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 20243390.0000 - accuracy: 0.4680 - val_loss: 5822075.0000 - val_accuracy: 0.5052\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5882957.5000 - accuracy: 0.4994 - val_loss: 15713611.0000 - val_accuracy: 0.5155\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 14897536.0000 - accuracy: 0.5302 - val_loss: 17741736.0000 - val_accuracy: 0.5155\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 16931982.0000 - accuracy: 0.5320 - val_loss: 11393316.0000 - val_accuracy: 0.5176\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 10873843.0000 - accuracy: 0.5325INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 10873843.0000 - accuracy: 0.5325 - val_loss: 4980065.0000 - val_accuracy: 0.5072\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5185131.0000 - accuracy: 0.5024 - val_loss: 9744826.0000 - val_accuracy: 0.4741\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11002209.0000 - accuracy: 0.4651 - val_loss: 10297501.0000 - val_accuracy: 0.4803\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 11574946.0000 - accuracy: 0.4633 - val_loss: 5807988.0000 - val_accuracy: 0.4928\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6392232.5000 - accuracy: 0.4633 - val_loss: 5294149.5000 - val_accuracy: 0.5010\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5109585.0000 - accuracy: 0.5148 - val_loss: 8873961.0000 - val_accuracy: 0.5238\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8399703.0000 - accuracy: 0.5320 - val_loss: 8556146.0000 - val_accuracy: 0.5217\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 8094712.0000 - accuracy: 0.5331INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 8094712.0000 - accuracy: 0.5331 - val_loss: 4921989.0000 - val_accuracy: 0.4969\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 4696634.5000 - accuracy: 0.5243INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 4696634.5000 - accuracy: 0.5243 - val_loss: 4032499.2500 - val_accuracy: 0.4865\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4187739.0000 - accuracy: 0.4893 - val_loss: 6216937.0000 - val_accuracy: 0.4803\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 6658220.0000 - accuracy: 0.4675 - val_loss: 5290763.5000 - val_accuracy: 0.4886\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 5631575.5000 - accuracy: 0.4710INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 5631575.5000 - accuracy: 0.4710 - val_loss: 3078855.7500 - val_accuracy: 0.4845\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3102322.0000 - accuracy: 0.5089 - val_loss: 4621278.5000 - val_accuracy: 0.5010\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4323750.0000 - accuracy: 0.5249 - val_loss: 5598412.0000 - val_accuracy: 0.5093\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5238837.5000 - accuracy: 0.5302 - val_loss: 4110438.2500 - val_accuracy: 0.4928\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3813620.7500 - accuracy: 0.5254INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 3813620.7500 - accuracy: 0.5254 - val_loss: 2793892.7500 - val_accuracy: 0.5052\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2750507.2500 - accuracy: 0.5189 - val_loss: 3999475.2500 - val_accuracy: 0.4990\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4130108.2500 - accuracy: 0.4834 - val_loss: 3798354.5000 - val_accuracy: 0.4907\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 3911830.7500 - accuracy: 0.4882INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 3911830.7500 - accuracy: 0.4882 - val_loss: 2618900.7500 - val_accuracy: 0.5093\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2515725.7500 - accuracy: 0.5178 - val_loss: 3396487.5000 - val_accuracy: 0.4928\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3113094.2500 - accuracy: 0.5260 - val_loss: 3931059.7500 - val_accuracy: 0.5093\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3595393.2500 - accuracy: 0.5331 - val_loss: 2907092.2500 - val_accuracy: 0.4990\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2640347.2500 - accuracy: 0.5237INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 2640347.2500 - accuracy: 0.5237 - val_loss: 2464219.5000 - val_accuracy: 0.4886\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2369015.2500 - accuracy: 0.5243 - val_loss: 3090846.7500 - val_accuracy: 0.4845\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3085885.2500 - accuracy: 0.4935 - val_loss: 2585680.2500 - val_accuracy: 0.4969\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2502691.2500 - accuracy: 0.5136INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 2502691.2500 - accuracy: 0.5136 - val_loss: 2325203.0000 - val_accuracy: 0.5238\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2071187.5000 - accuracy: 0.5314 - val_loss: 3012959.7500 - val_accuracy: 0.5072\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2641476.5000 - accuracy: 0.5385 - val_loss: 2645695.7500 - val_accuracy: 0.5052\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2295071.0000 - accuracy: 0.5402INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2295071.0000 - accuracy: 0.5402 - val_loss: 2069427.0000 - val_accuracy: 0.5072\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1848635.8750 - accuracy: 0.5373 - val_loss: 2443756.0000 - val_accuracy: 0.4720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2318748.2500 - accuracy: 0.5083 - val_loss: 2141503.2500 - val_accuracy: 0.4948\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1938460.1250 - accuracy: 0.5243 - val_loss: 2116664.2500 - val_accuracy: 0.5280\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1766475.2500 - accuracy: 0.5533 - val_loss: 2464373.7500 - val_accuracy: 0.4990\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 2051274.5000 - accuracy: 0.5515INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 2051274.5000 - accuracy: 0.5515 - val_loss: 2061751.5000 - val_accuracy: 0.5280\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1682559.7500 - accuracy: 0.5586INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 1682559.7500 - accuracy: 0.5586 - val_loss: 1989311.5000 - val_accuracy: 0.4948\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1674685.7500 - accuracy: 0.5408 - val_loss: 2077550.0000 - val_accuracy: 0.5031\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1787233.0000 - accuracy: 0.5219INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 1787233.0000 - accuracy: 0.5219 - val_loss: 1843431.1250 - val_accuracy: 0.5300\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1455154.1250 - accuracy: 0.5609 - val_loss: 2062288.7500 - val_accuracy: 0.4969\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1644227.7500 - accuracy: 0.5580 - val_loss: 1922028.6250 - val_accuracy: 0.4928\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1501457.0000 - accuracy: 0.5692INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 1501457.0000 - accuracy: 0.5692 - val_loss: 1813453.5000 - val_accuracy: 0.5135\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1401818.1250 - accuracy: 0.5645 - val_loss: 1896922.6250 - val_accuracy: 0.5052\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1499039.5000 - accuracy: 0.5467INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 1499039.5000 - accuracy: 0.5467 - val_loss: 1734006.2500 - val_accuracy: 0.5093\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1280907.3750 - accuracy: 0.5757 - val_loss: 1854654.3750 - val_accuracy: 0.5052\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1380823.1250 - accuracy: 0.5763 - val_loss: 1754759.8750 - val_accuracy: 0.4948\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1256136.8750 - accuracy: 0.5822INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 1256136.8750 - accuracy: 0.5822 - val_loss: 1733059.3750 - val_accuracy: 0.5155\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1248457.3750 - accuracy: 0.5704INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 1248457.3750 - accuracy: 0.5704 - val_loss: 1718614.6250 - val_accuracy: 0.5114\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1222784.7500 - accuracy: 0.5716INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 1222784.7500 - accuracy: 0.5716 - val_loss: 1701208.8750 - val_accuracy: 0.4969\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1142517.3750 - accuracy: 0.5959 - val_loss: 1744466.5000 - val_accuracy: 0.5072\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1173733.5000 - accuracy: 0.5959INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 1173733.5000 - accuracy: 0.5959 - val_loss: 1638779.0000 - val_accuracy: 0.5031\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1060034.7500 - accuracy: 0.6006 - val_loss: 1652391.3750 - val_accuracy: 0.5155\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1103069.8750 - accuracy: 0.5686INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 1103069.8750 - accuracy: 0.5686 - val_loss: 1610867.5000 - val_accuracy: 0.5031\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1000258.2500 - accuracy: 0.6136 - val_loss: 1675497.2500 - val_accuracy: 0.5031\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 1053699.3750 - accuracy: 0.6101INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 1053699.3750 - accuracy: 0.6101 - val_loss: 1579836.2500 - val_accuracy: 0.5072\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 951105.1250 - accuracy: 0.6154 - val_loss: 1602295.1250 - val_accuracy: 0.5176\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 988009.8750 - accuracy: 0.5834INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 988009.8750 - accuracy: 0.5834 - val_loss: 1564993.0000 - val_accuracy: 0.5176\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 904404.2500 - accuracy: 0.6296 - val_loss: 1597657.5000 - val_accuracy: 0.4928\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 926469.4375 - accuracy: 0.6189INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 926469.4375 - accuracy: 0.6189 - val_loss: 1544488.1250 - val_accuracy: 0.5010\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 867575.1250 - accuracy: 0.6130INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 867575.1250 - accuracy: 0.6130 - val_loss: 1543482.2500 - val_accuracy: 0.5052\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 861294.1875 - accuracy: 0.6065 - val_loss: 1562601.3750 - val_accuracy: 0.5010\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 849474.8125 - accuracy: 0.6349INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 849474.8125 - accuracy: 0.6349 - val_loss: 1530962.0000 - val_accuracy: 0.5114\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 802850.0625 - accuracy: 0.6462 - val_loss: 1538808.7500 - val_accuracy: 0.5010\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 820093.8750 - accuracy: 0.6130INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 820093.8750 - accuracy: 0.6130 - val_loss: 1515213.0000 - val_accuracy: 0.5114\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 758084.1875 - accuracy: 0.6479 - val_loss: 1547912.7500 - val_accuracy: 0.4990\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 774053.5625 - accuracy: 0.6391 - val_loss: 1516915.1250 - val_accuracy: 0.5031\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 747122.0000 - accuracy: 0.6314INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 747122.0000 - accuracy: 0.6314 - val_loss: 1500183.5000 - val_accuracy: 0.5072\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 706441.7500 - accuracy: 0.6479 - val_loss: 1534736.6250 - val_accuracy: 0.5114\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 727491.5000 - accuracy: 0.6444INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 727491.5000 - accuracy: 0.6444 - val_loss: 1492052.8750 - val_accuracy: 0.5031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 679104.8125 - accuracy: 0.6450INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 679104.8125 - accuracy: 0.6450 - val_loss: 1482923.7500 - val_accuracy: 0.4990\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 656617.7500 - accuracy: 0.6598 - val_loss: 1491386.3750 - val_accuracy: 0.5072\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 658692.3750 - accuracy: 0.6686INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 658692.3750 - accuracy: 0.6686 - val_loss: 1456825.0000 - val_accuracy: 0.5010\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 621718.7500 - accuracy: 0.6657INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 621718.7500 - accuracy: 0.6657 - val_loss: 1443652.3750 - val_accuracy: 0.4969\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 607696.3750 - accuracy: 0.6663 - val_loss: 1447704.8750 - val_accuracy: 0.5072\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 614358.0625 - accuracy: 0.6763INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 614358.0625 - accuracy: 0.6763 - val_loss: 1432739.8750 - val_accuracy: 0.4990\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 586315.7500 - accuracy: 0.6609INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 586315.7500 - accuracy: 0.6609 - val_loss: 1417483.8750 - val_accuracy: 0.4907\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 557818.1875 - accuracy: 0.6799 - val_loss: 1422033.5000 - val_accuracy: 0.5052\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 554333.7500 - accuracy: 0.6811 - val_loss: 1426318.8750 - val_accuracy: 0.5072\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 543795.4375 - accuracy: 0.6757INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 543795.4375 - accuracy: 0.6757 - val_loss: 1412226.0000 - val_accuracy: 0.5093\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 520313.0625 - accuracy: 0.6852INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 520313.0625 - accuracy: 0.6852 - val_loss: 1404292.6250 - val_accuracy: 0.5010\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 504835.2500 - accuracy: 0.6876INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 504835.2500 - accuracy: 0.6876 - val_loss: 1399560.0000 - val_accuracy: 0.5052\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 501691.6875 - accuracy: 0.6893INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 501691.6875 - accuracy: 0.6893 - val_loss: 1395397.2500 - val_accuracy: 0.5176\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 503038.7188 - accuracy: 0.6959INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 503038.7188 - accuracy: 0.6959 - val_loss: 1383305.2500 - val_accuracy: 0.5114\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 487868.9062 - accuracy: 0.6858INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 487868.9062 - accuracy: 0.6858 - val_loss: 1362049.8750 - val_accuracy: 0.5072\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 467859.5938 - accuracy: 0.6964INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 467859.5938 - accuracy: 0.6964 - val_loss: 1348104.5000 - val_accuracy: 0.5238\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 448098.7188 - accuracy: 0.7089INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 448098.7188 - accuracy: 0.7089 - val_loss: 1348044.5000 - val_accuracy: 0.5176\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 438791.1250 - accuracy: 0.7077 - val_loss: 1355492.7500 - val_accuracy: 0.5197\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 443191.2188 - accuracy: 0.6982 - val_loss: 1378147.1250 - val_accuracy: 0.5176\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 449657.9062 - accuracy: 0.6905 - val_loss: 1363297.7500 - val_accuracy: 0.5259\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 436318.3750 - accuracy: 0.7036 - val_loss: 1363040.3750 - val_accuracy: 0.5155\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 420312.2500 - accuracy: 0.6982INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 420312.2500 - accuracy: 0.6982 - val_loss: 1336672.8750 - val_accuracy: 0.5176\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 396121.5000 - accuracy: 0.7207INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 396121.5000 - accuracy: 0.7207 - val_loss: 1327663.0000 - val_accuracy: 0.5135\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 377625.0000 - accuracy: 0.7195 - val_loss: 1328166.2500 - val_accuracy: 0.5217\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 373169.6562 - accuracy: 0.7160 - val_loss: 1335227.0000 - val_accuracy: 0.5176\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 384124.4688 - accuracy: 0.7254 - val_loss: 1377047.2500 - val_accuracy: 0.5176\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 411862.4062 - accuracy: 0.6817 - val_loss: 1377928.6250 - val_accuracy: 0.5383\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 418992.5625 - accuracy: 0.7071 - val_loss: 1420656.8750 - val_accuracy: 0.5176\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 444063.8125 - accuracy: 0.6633 - val_loss: 1398212.3750 - val_accuracy: 0.5280\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 428598.5312 - accuracy: 0.6982 - val_loss: 1385116.2500 - val_accuracy: 0.5135\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 381219.2812 - accuracy: 0.6929 - val_loss: 1331342.0000 - val_accuracy: 0.4969\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 331150.5312 - accuracy: 0.7473INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 331150.5312 - accuracy: 0.7473 - val_loss: 1322247.6250 - val_accuracy: 0.4990\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 312015.5938 - accuracy: 0.7533 - val_loss: 1357317.8750 - val_accuracy: 0.5176\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 340010.7500 - accuracy: 0.7071 - val_loss: 1371007.5000 - val_accuracy: 0.5217\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 369103.2188 - accuracy: 0.7243 - val_loss: 1386539.1250 - val_accuracy: 0.5135\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 362572.4062 - accuracy: 0.6959 - val_loss: 1356025.5000 - val_accuracy: 0.5114\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 329853.2500 - accuracy: 0.7426 - val_loss: 1343961.0000 - val_accuracy: 0.5114\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 290370.1250 - accuracy: 0.7444 - val_loss: 1331228.1250 - val_accuracy: 0.5093\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 274008.7188 - accuracy: 0.7568 - val_loss: 1343160.7500 - val_accuracy: 0.5114\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 291331.5312 - accuracy: 0.7621 - val_loss: 1353224.8750 - val_accuracy: 0.5217\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 288503.3125 - accuracy: 0.7284 - val_loss: 1330817.5000 - val_accuracy: 0.5093\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 268446.6875 - accuracy: 0.7692INFO:tensorflow:Assets written to: best_model.hdfs\\assets\n",
      "1/1 [==============================] - 1s 1s/step - loss: 268446.6875 - accuracy: 0.7692 - val_loss: 1316654.8750 - val_accuracy: 0.5031\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 249095.9375 - accuracy: 0.7692 - val_loss: 1317086.1250 - val_accuracy: 0.5093\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 245321.5469 - accuracy: 0.7645 - val_loss: 1321260.2500 - val_accuracy: 0.5093\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 254573.4062 - accuracy: 0.7746 - val_loss: 1350140.3750 - val_accuracy: 0.5197\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 275000.0938 - accuracy: 0.7231 - val_loss: 1368381.7500 - val_accuracy: 0.5321\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 317438.3438 - accuracy: 0.7254 - val_loss: 1428451.8750 - val_accuracy: 0.5114\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 375344.1562 - accuracy: 0.6722 - val_loss: 1450875.1250 - val_accuracy: 0.5362\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 420742.2812 - accuracy: 0.6929 - val_loss: 1386991.0000 - val_accuracy: 0.5010\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 289203.5312 - accuracy: 0.7148 - val_loss: 1331362.3750 - val_accuracy: 0.5114\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 222565.5156 - accuracy: 0.7870 - val_loss: 1340037.2500 - val_accuracy: 0.5052\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 227761.3125 - accuracy: 0.7882 - val_loss: 1396932.6250 - val_accuracy: 0.5072\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 277370.4375 - accuracy: 0.7189 - val_loss: 1418633.6250 - val_accuracy: 0.5404\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 331766.8438 - accuracy: 0.7231 - val_loss: 1382875.2500 - val_accuracy: 0.5197\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 262848.0625 - accuracy: 0.7278 - val_loss: 1330818.0000 - val_accuracy: 0.5072\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 203528.7031 - accuracy: 0.8036 - val_loss: 1329142.5000 - val_accuracy: 0.5052\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 199008.1094 - accuracy: 0.8036 - val_loss: 1352537.7500 - val_accuracy: 0.5031\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 225277.6719 - accuracy: 0.7568 - val_loss: 1343462.3750 - val_accuracy: 0.5176\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 208521.9844 - accuracy: 0.7905 - val_loss: 1322037.3750 - val_accuracy: 0.4990\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 180663.7188 - accuracy: 0.8036 - val_loss: 1325828.1250 - val_accuracy: 0.4948\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 182961.5469 - accuracy: 0.8006 - val_loss: 1335779.6250 - val_accuracy: 0.5135\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 186467.7812 - accuracy: 0.8018 - val_loss: 1324182.1250 - val_accuracy: 0.5010\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 175545.6406 - accuracy: 0.7988 - val_loss: 1317656.3750 - val_accuracy: 0.5093\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 160288.0781 - accuracy: 0.8231 - val_loss: 1324588.7500 - val_accuracy: 0.5031\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 167089.2656 - accuracy: 0.8101 - val_loss: 1333824.1250 - val_accuracy: 0.5031\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 178245.0781 - accuracy: 0.7852 - val_loss: 1344703.3750 - val_accuracy: 0.5135\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 191024.5000 - accuracy: 0.7917 - val_loss: 1335416.1250 - val_accuracy: 0.5052\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 170854.9375 - accuracy: 0.7953 - val_loss: 1325343.8750 - val_accuracy: 0.5031\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 152032.6094 - accuracy: 0.8249 - val_loss: 1323063.0000 - val_accuracy: 0.5114\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 140592.3594 - accuracy: 0.8254 - val_loss: 1328744.1250 - val_accuracy: 0.5052\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 141493.2344 - accuracy: 0.8213 - val_loss: 1335502.0000 - val_accuracy: 0.5114\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 147037.7344 - accuracy: 0.8254 - val_loss: 1338453.3750 - val_accuracy: 0.5031\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 148308.7656 - accuracy: 0.8053 - val_loss: 1343749.0000 - val_accuracy: 0.5114\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 152566.1094 - accuracy: 0.8124 - val_loss: 1339264.5000 - val_accuracy: 0.5010\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 148238.8750 - accuracy: 0.7976 - val_loss: 1351535.1250 - val_accuracy: 0.5114\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 162245.2188 - accuracy: 0.7994 - val_loss: 1350437.3750 - val_accuracy: 0.4948\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 172423.7188 - accuracy: 0.7663 - val_loss: 1410112.2500 - val_accuracy: 0.5321\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 251995.2656 - accuracy: 0.7420 - val_loss: 1452854.2500 - val_accuracy: 0.5072\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 310130.4375 - accuracy: 0.6834 - val_loss: 1514497.6250 - val_accuracy: 0.5300\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 389711.1875 - accuracy: 0.7000 - val_loss: 1390369.0000 - val_accuracy: 0.5072\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 189485.3438 - accuracy: 0.7521 - val_loss: 1343896.3750 - val_accuracy: 0.5114\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 123234.5156 - accuracy: 0.8497 - val_loss: 1356198.0000 - val_accuracy: 0.5135\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 136091.6875 - accuracy: 0.8385 - val_loss: 1379772.1250 - val_accuracy: 0.5052\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 162325.6094 - accuracy: 0.7834 - val_loss: 1364992.1250 - val_accuracy: 0.5135\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 149005.7656 - accuracy: 0.8207 - val_loss: 1331110.1250 - val_accuracy: 0.5010\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 111077.0391 - accuracy: 0.8479 - val_loss: 1343997.7500 - val_accuracy: 0.4948\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 131467.2188 - accuracy: 0.8225 - val_loss: 1357381.7500 - val_accuracy: 0.5300\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 148324.7344 - accuracy: 0.8124 - val_loss: 1322659.1250 - val_accuracy: 0.5052\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 105684.1250 - accuracy: 0.8527 - val_loss: 1335619.6250 - val_accuracy: 0.4948\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 117732.8281 - accuracy: 0.8349 - val_loss: 1367783.3750 - val_accuracy: 0.5259\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 154887.7500 - accuracy: 0.8012 - val_loss: 1355911.8750 - val_accuracy: 0.4990\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 130917.6797 - accuracy: 0.8047 - val_loss: 1337603.3750 - val_accuracy: 0.5197\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 102412.5625 - accuracy: 0.8609 - val_loss: 1341540.1250 - val_accuracy: 0.5155\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 100917.8125 - accuracy: 0.8633 - val_loss: 1356711.3750 - val_accuracy: 0.5010\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 113846.1328 - accuracy: 0.8337 - val_loss: 1346687.2500 - val_accuracy: 0.5114\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 101312.7031 - accuracy: 0.8633 - val_loss: 1341378.1250 - val_accuracy: 0.5010\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 91226.1016 - accuracy: 0.8763 - val_loss: 1349979.2500 - val_accuracy: 0.4928\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 95259.8516 - accuracy: 0.8645 - val_loss: 1343742.7500 - val_accuracy: 0.4990\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 84915.3828 - accuracy: 0.8822 - val_loss: 1350539.3750 - val_accuracy: 0.5072\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 91311.2266 - accuracy: 0.8692 - val_loss: 1353934.5000 - val_accuracy: 0.4928\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 92112.4922 - accuracy: 0.8592 - val_loss: 1343180.8750 - val_accuracy: 0.5052\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 80978.0156 - accuracy: 0.8852 - val_loss: 1342293.1250 - val_accuracy: 0.5052\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 81473.8828 - accuracy: 0.8822 - val_loss: 1345259.8750 - val_accuracy: 0.4990\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 87516.1484 - accuracy: 0.8633 - val_loss: 1337370.3750 - val_accuracy: 0.5114\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 77573.7109 - accuracy: 0.8888 - val_loss: 1337064.0000 - val_accuracy: 0.5072\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 75044.1250 - accuracy: 0.8899 - val_loss: 1338036.2500 - val_accuracy: 0.4990\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 76662.2266 - accuracy: 0.8734 - val_loss: 1336523.1250 - val_accuracy: 0.5093\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 70959.0000 - accuracy: 0.8959 - val_loss: 1338713.7500 - val_accuracy: 0.5010\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 71715.9453 - accuracy: 0.8893 - val_loss: 1343726.3750 - val_accuracy: 0.4928\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 80521.0156 - accuracy: 0.8615 - val_loss: 1350227.5000 - val_accuracy: 0.5176\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 95584.3750 - accuracy: 0.8408 - val_loss: 1358727.2500 - val_accuracy: 0.5052\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 111732.4062 - accuracy: 0.7994 - val_loss: 1409446.5000 - val_accuracy: 0.5259\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 202090.2188 - accuracy: 0.7598 - val_loss: 1447923.6250 - val_accuracy: 0.5010\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 249064.8594 - accuracy: 0.7000 - val_loss: 1537354.5000 - val_accuracy: 0.5424\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 371537.6875 - accuracy: 0.6899 - val_loss: 1436204.3750 - val_accuracy: 0.5052\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 216868.2969 - accuracy: 0.7195 - val_loss: 1377881.0000 - val_accuracy: 0.5217\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 133375.0000 - accuracy: 0.8112 - val_loss: 1334375.6250 - val_accuracy: 0.4990\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 68333.9609 - accuracy: 0.8947 - val_loss: 1386162.1250 - val_accuracy: 0.4948\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 123158.5547 - accuracy: 0.8047 - val_loss: 1428205.1250 - val_accuracy: 0.5238\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 194944.9844 - accuracy: 0.7710 - val_loss: 1370794.5000 - val_accuracy: 0.4928\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 98245.7031 - accuracy: 0.8373 - val_loss: 1345659.3750 - val_accuracy: 0.4907\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 71589.5156 - accuracy: 0.8817 - val_loss: 1363561.3750 - val_accuracy: 0.5259\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 103834.6328 - accuracy: 0.8479 - val_loss: 1338405.3750 - val_accuracy: 0.5031\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 67438.3594 - accuracy: 0.8870 - val_loss: 1353532.3750 - val_accuracy: 0.5114\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 83814.6875 - accuracy: 0.8562 - val_loss: 1363536.8750 - val_accuracy: 0.5300\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 104317.7500 - accuracy: 0.8361 - val_loss: 1329781.7500 - val_accuracy: 0.4990\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 61141.3672 - accuracy: 0.9077 - val_loss: 1366136.1250 - val_accuracy: 0.5072\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 98678.2500 - accuracy: 0.8254 - val_loss: 1403111.1250 - val_accuracy: 0.5280\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 152017.9688 - accuracy: 0.7864 - val_loss: 1358755.5000 - val_accuracy: 0.4990\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 74088.8672 - accuracy: 0.8692 - val_loss: 1379309.1250 - val_accuracy: 0.5093\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 87668.1562 - accuracy: 0.8379 - val_loss: 1435060.8750 - val_accuracy: 0.5321\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 180621.1406 - accuracy: 0.7746 - val_loss: 1392013.7500 - val_accuracy: 0.5072\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 83243.2266 - accuracy: 0.8467 - val_loss: 1379903.8750 - val_accuracy: 0.4990\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 68794.9141 - accuracy: 0.8828 - val_loss: 1376824.7500 - val_accuracy: 0.5217\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 88247.2344 - accuracy: 0.8586 - val_loss: 1349112.8750 - val_accuracy: 0.5010\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 54862.6953 - accuracy: 0.9195 - val_loss: 1391186.5000 - val_accuracy: 0.5135\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 85528.8828 - accuracy: 0.8302 - val_loss: 1395555.7500 - val_accuracy: 0.5300\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 108045.6016 - accuracy: 0.8402 - val_loss: 1341545.7500 - val_accuracy: 0.4969\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 52676.1172 - accuracy: 0.9178 - val_loss: 1392522.3750 - val_accuracy: 0.5072\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 110501.1875 - accuracy: 0.7923 - val_loss: 1467672.8750 - val_accuracy: 0.5362\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 214227.1094 - accuracy: 0.7385 - val_loss: 1424689.7500 - val_accuracy: 0.5052\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 139259.2031 - accuracy: 0.7515 - val_loss: 1377290.5000 - val_accuracy: 0.5259\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"] )\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath=\"best_model.hdfs\", monitor = \"val_loss\",\n",
    "                                  save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=100, restore_best_weights=True)\n",
    "callbacks = [model_checkpoint, early_stopping]\n",
    "\n",
    "train_history = model.fit(x_train,to_categorical(y_train),\n",
    "                         validation_data=(x_val, to_categorical(y_val)),\n",
    "                         batch_size=2048, epochs=1000, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b5d149",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_yscale(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_history\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(train_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "fig, axes = plt.subplots(2,1,figsize=(16,12))\n",
    "\n",
    "# \n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].plot(train_history.history[\"loss\"], label=\"Training\")\n",
    "axes[0].plot(train_history.history[\"val_loss\"], label=\"Validation\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].plot(train_history.history[\"accuracy\"], label=\"Training\")\n",
    "axes[1].plot(train_history.history[\"val_accuracy\"], label=\"Validation\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f051e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train situaction's 訓練結果畫出來 \n",
    "# up pic　loss function　validation data vs training data\n",
    "# ＬＯＳＳ值越低　代表模型準確度越高　訓練模型只會餵入ＴＲＡＩＮＩＮＧ　ＤＡＴＡ所以ＬＯＳＳ值一錠是永遠往下的\n",
    "#代表模型越來越你和ＴＲＡ　ＤＡＴＡ　但是這個的準確值可能只對ＴＲＡＩＮＤＡＴＡ準確　對其他的就不行\n",
    "#如果真是這樣　這個模型只會ＯＶＥＲ　ＦＩＴＴＩＮＧ　失去泛用性　這樣的模型是沒用的\n",
    "#為了監察何時開始ＯＶＥＲ　ＦＩＴ　唯有利用ＶＡＬＩ　ＤＡＴＡ\n",
    "#在每個回合結束時讓模型跑一下ＶＡＬＩ　\n",
    "#算出ＶＡＬＩ　ＬＯＳＳ\n",
    "#一開始有下降　代表準確度的確有提升又不失泛用性　但后後來ＯＶＥＲ　ＦＩＴＴＩＮＧ漸漸浮現\n",
    "#ＶＡＬ　ＬＯＳＳ不再下降\n",
    "#第二幅圖是看準確度　跟ＬＯＳＳ相反　準確度是越高越好\n",
    "#同樣道理　ＴＡＲＩＮ的ＡＣＵ只會向上　而ＶＡＬ的ＡＣＵ會先向上　然後因為模型ＯＶＥＲ　ＦＩＴ而停止轉而向下\n",
    "#ＡＣＵ曲線通常不會像ＬＯＳＳ曲線平滑　因為ＡＣＵ不是連續函數\n",
    "#最終選出來用的模型有兩個　一個是ＶＡＬ　ＬＯＳＳ值最低的回合\n",
    "#另一個是ＶＡＬ　ＡＣＵ最高的回合\n",
    "#ＡＣＵ表顯不穩定　所以選擇ＬＯＳＳ\n",
    "#ＥＡＲＬＹ　ＳＴＯＰ　的ＣＡＬＬＢＡＣＫ監察到最低值的ＬＯＳＳ而結束整個訓練　而這一個最低ＬＯＳＳ值得模型也被儲存了起來\n",
    "#因為有ＭＯＤＥＬ　ＣＨＥＣＫＰＯＩＮＴ這個ＣＡＬＬＢＡＣＫ　ＦＵＮＣＴＩＯＮ\n",
    "\n",
    "#測試集就是要拿來量度最終的準確度\n",
    "#剛剛訓練好的模型已被ＭＯＤＥＬ　ＣＨＥＣＫＰＯＩＮＴ程序儲存\n",
    "#而ＴＥＳＴ　ＤＡＴＡＳＥＴ在一開始建立數據集時已經用好　他跟　ＴＲＡＩＮＤＡＴＡ　ＶＡＬＤＡＴＡ\n",
    "#一同被放到ＮＰＺ檔案裡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
