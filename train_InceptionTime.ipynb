{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e35b3c7",
   "metadata": {},
   "source": [
    "# Load datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8894cf",
   "metadata": {},
   "source": [
    "# Stock trend classifiaction_train Inception Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f315ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Bull</th>\n",
       "      <th>Bear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>888</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>263</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Bull  Bear\n",
       "0   train   888   803\n",
       "1     val   263   220\n",
       "2    test   120   120"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CLASSES = [ \"Bull\" , \"Bear\"  ]  \n",
    "LABEL_BULL = CLASSES.index( \"Bull\" )\n",
    "LABEL_BEAR = CLASSES.index( \"Bear\" )\n",
    "\n",
    "datasets = np.load(\"datasets.npz\")\n",
    "x_train, y_train = datasets[\"x_train\"],datasets[\"y_train\"]\n",
    "x_val,y_val = datasets[\"x_val\"],datasets[\"y_val\"]\n",
    "x_test,y_test = datasets[\"x_test\"],datasets[\"y_test\"]\n",
    "                                             \n",
    "# Label distribution \n",
    "label_distribution = pd.DataFrame([{\"Dataset\" : \"train\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_train == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_train == LABEL_BEAR)},\n",
    "                                                         {\"Dataset\" : \"val\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_val == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_val == LABEL_BEAR)},\n",
    "                                                         {\"Dataset\" : \"test\",\n",
    "                                                         \"Bull\":np.count_nonzero(y_test == LABEL_BULL),\n",
    "                                                         \"Bear\": np.count_nonzero(y_test == LABEL_BEAR)}])\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101c272",
   "metadata": {},
   "source": [
    "# Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f238f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 7)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 100, 32)      224         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 100, 7)       0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 100, 32)      3072        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 100, 32)      5120        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 100, 32)      7168        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 100, 32)      224         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 100, 128)     0           ['conv1d_1[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]',               \n",
      "                                                                  'conv1d_3[0][0]',               \n",
      "                                                                  'conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 100, 128)    512         ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 100, 128)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 100, 32)      4096        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 100, 128)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 100, 32)      3072        ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 100, 32)      5120        ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 100, 32)      7168        ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 100, 32)      4096        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 100, 128)     0           ['conv1d_6[0][0]',               \n",
      "                                                                  'conv1d_7[0][0]',               \n",
      "                                                                  'conv1d_8[0][0]',               \n",
      "                                                                  'conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100, 128)    512         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 100, 128)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 100, 32)      4096        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 100, 128)    0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 100, 32)      3072        ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 100, 32)      5120        ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 100, 32)      7168        ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 100, 32)      4096        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 100, 128)     0           ['conv1d_11[0][0]',              \n",
      "                                                                  'conv1d_12[0][0]',              \n",
      "                                                                  'conv1d_13[0][0]',              \n",
      "                                                                  'conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 100, 128)     896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 100, 128)    512         ['concatenate_2[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 100, 128)    512         ['conv1d_15[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 100, 128)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 100, 128)     0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 100, 128)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 100, 32)      4096        ['activation_3[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max_pooling1d_3 (MaxPooling1D)  (None, 100, 128)    0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 100, 32)      3072        ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 100, 32)      5120        ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 100, 32)      7168        ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 100, 32)      4096        ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 100, 128)     0           ['conv1d_17[0][0]',              \n",
      "                                                                  'conv1d_18[0][0]',              \n",
      "                                                                  'conv1d_19[0][0]',              \n",
      "                                                                  'conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 128)    512         ['concatenate_3[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 100, 128)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 100, 32)      4096        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 100, 128)    0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 100, 32)      3072        ['conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 100, 32)      5120        ['conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 100, 32)      7168        ['conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 100, 32)      4096        ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 100, 128)     0           ['conv1d_22[0][0]',              \n",
      "                                                                  'conv1d_23[0][0]',              \n",
      "                                                                  'conv1d_24[0][0]',              \n",
      "                                                                  'conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 100, 128)    512         ['concatenate_4[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 100, 128)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 100, 32)      4096        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 100, 128)    0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 100, 32)      3072        ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 100, 32)      5120        ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 100, 32)      7168        ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 100, 32)      4096        ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 100, 128)     0           ['conv1d_27[0][0]',              \n",
      "                                                                  'conv1d_28[0][0]',              \n",
      "                                                                  'conv1d_29[0][0]',              \n",
      "                                                                  'conv1d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 100, 128)     16384       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 128)    512         ['concatenate_5[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 128)    512         ['conv1d_31[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 128)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 100, 128)     0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 128)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['activation_7[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            258         ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 155,202\n",
      "Trainable params: 153,154\n",
      "Non-trainable params: 2,048\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Concatenate, \\\n",
    "                                                        BatchNormalization, Activation, \\\n",
    "                                                        Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "def inception_module(input_tensor):\n",
    "    bottleneck = Conv1D(filters=32, kernel_size=1, padding=\"same\", activation=None,\n",
    "                       use_bias=False) (input_tensor)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=None,\n",
    "                       use_bias=False) (bottleneck)\n",
    "    conv5 = Conv1D(filters=32, kernel_size=5, padding=\"same\", activation=None,\n",
    "                       use_bias=False) (bottleneck)\n",
    "    conv7 = Conv1D(filters=32, kernel_size=7, padding=\"same\", activation=None,\n",
    "                       use_bias=False) (bottleneck)\n",
    "    mp = MaxPooling1D(pool_size=3, strides=1,padding=\"same\")(input_tensor)\n",
    "    mpbottleneck = Conv1D(filters=32, kernel_size=1, padding=\"same\",activation=None,\n",
    "                         use_bias=False)(mp)\n",
    "    \n",
    "    x = Concatenate(axis=-1)([conv3,conv5,conv7, mpbottleneck])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def shortcut_layer(input_tensor1, input_tensor2):\n",
    "    shortcut = Conv1D(filters=input_tensor2.shape[-1], kernel_size=1, padding=\"same\", activation=None, use_bias=False)(input_tensor1)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([shortcut, input_tensor2])\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "#Build model\n",
    "n_time_steps = x_train.shape[1]\n",
    "n_features = x_train.shape[2]\n",
    "\n",
    "input_layer = Input(shape=(n_time_steps, n_features))\n",
    "x = input_layer\n",
    "input_residual = input_layer\n",
    "\n",
    "for i in range(6):\n",
    "    x = inception_module(x)\n",
    "    \n",
    "    if i % 3 == 2 :\n",
    "        x = shortcut_layer(input_residual, x)\n",
    "        input_residual = x\n",
    "\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "output_layer = Dense(len(CLASSES), activation=\"softmax\" )(x)\n",
    "\n",
    "model = Model(inputs = input_layer, outputs= output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc91a9f",
   "metadata": {},
   "source": [
    "#  Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2073c0f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, EarlyStopping\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                   save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath=\"best_model.hdf5\", monitor =\"val_loss\",\n",
    "                                  save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience= 100, restore_best_weights=True)\n",
    "callbacks = [model_checkpoint, early_stopping]\n",
    "\n",
    "train_history = model.fit(x_train, to_categorical(y_train),\n",
    "                         validation_data=(x_val, to_categorical(y_val)),\n",
    "                         batch_size= 2048, epochs=1000, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec242b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_yscale(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_history\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(train_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "fig, axes = plt.subplots(2,1,figsize=(16,12))\n",
    "\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[0].plot(train_history.history[\"loss\"], label=\"Training\")\n",
    "axes[0].plot(train_history.history[\"val_loss\"], label= \"Validation\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].plot(train_history.history[\"accuracy\"], label=\"Training\")\n",
    "axes[1].plot(train_history.history[\"val_accuracy\"], label= \"Validation\")\n",
    "axes[1].legend()\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75854b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
